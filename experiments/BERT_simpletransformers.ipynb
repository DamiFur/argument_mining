{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0306 13:34:19.743310 140305489397504 file_utils.py:35] PyTorch version 1.0.1 available.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import WEIGHTS_NAME, BertConfig, BertForTokenClassification, BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "import sklearn\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "\n",
    "from io import open\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"bert\": (BertConfig, BertForTokenClassification, BertTokenizer),\n",
    "}\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for token classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, words, labels):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            words: list. The words of the sequence.\n",
    "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.words = words\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"text\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "n_gpu = 1\n",
    "\n",
    "# Set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0306 13:34:27.927412 140305489397504 configuration_utils.py:185] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /home/dfurman/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.fc076a4d5f1edf25ea3a2bd66e9f6f295dcd64c81dfef5b3f5a3eb2a82751ad1\n",
      "I0306 13:34:27.928565 140305489397504 configuration_utils.py:199] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0306 13:34:28.583698 140305489397504 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /home/dfurman/.cache/torch/transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0306 13:34:29.278102 140305489397504 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0306 13:34:41.892791 140305489397504 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0306 13:34:41.893879 140305489397504 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "    pad_token_label_id = CrossEntropyLoss().ignore_index\n",
    "\n",
    "    model_type = \"bert\"\n",
    "    config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "\n",
    "    bert_type = \"bert-large-uncased\"\n",
    "    config = config_class.from_pretrained(bert_type,\n",
    "                                              num_labels=2)\n",
    "    tokenizer = tokenizer_class.from_pretrained(bert_type,\n",
    "                                                    do_lower_case=True)\n",
    "    model = model_class.from_pretrained(bert_type, from_tf=False,\n",
    "                                            config=config)\n",
    "    model.to(device)\n",
    "\n",
    "    'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples,\n",
    "                                 label_list,\n",
    "                                 max_seq_length,\n",
    "                                 tokenizer,\n",
    "                                 cls_token_at_end=False,\n",
    "                                 cls_token=\"[CLS]\",\n",
    "                                 cls_token_segment_id=1,\n",
    "                                 sep_token=\"[SEP]\",\n",
    "                                 sep_token_extra=False,\n",
    "                                 pad_on_left=False,\n",
    "                                 pad_token=0,\n",
    "                                 pad_token_segment_id=0,\n",
    "                                 pad_token_label_id=-1,\n",
    "                                 sequence_a_segment_id=0,\n",
    "                                 mask_padding_with_zero=True):\n",
    "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
    "        `cls_token_at_end` define the location of the CLS token:\n",
    "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "#         if ex_index % 10000 == 0:\n",
    "#             print(\"Writing example {} of {}\".format(ex_index, len(examples)))\n",
    "#             print(\"E.g: {}\".format(example.words))\n",
    "\n",
    "        tokens = []\n",
    "        label_ids = []\n",
    "        for word, label in zip(example.words, example.labels):\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            tokens.extend(word_tokens)\n",
    "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
    "        \n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "        special_tokens_count = 3 if sep_token_extra else 2\n",
    "        if len(tokens) > max_seq_length - special_tokens_count:\n",
    "            tokens = tokens[:(max_seq_length - special_tokens_count)]\n",
    "            label_ids = label_ids[:(max_seq_length - special_tokens_count)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids:   0   0   0   0  0     0   0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens += [sep_token]\n",
    "        label_ids += [pad_token_label_id]\n",
    "        if sep_token_extra:\n",
    "            # roberta uses an extra separator b/w pairs of sentences\n",
    "            tokens += [sep_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        if cls_token_at_end:\n",
    "            tokens += [cls_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "            segment_ids += [cls_token_segment_id]\n",
    "        else:\n",
    "            tokens = [cls_token] + tokens\n",
    "            label_ids = [pad_token_label_id] + label_ids\n",
    "            segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
    "        else:\n",
    "            input_ids += ([pad_token] * padding_length)\n",
    "            input_mask += ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            segment_ids += ([pad_token_segment_id] * padding_length)\n",
    "            label_ids += ([pad_token_label_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "        \n",
    "        if ex_index > 100 and ex_index < 120:\n",
    "            print(\"Example {}\".format(ex_index))\n",
    "            print(list(zip(tokens, input_ids, label_ids)))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_ids=label_ids))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataloader):\n",
    "    eval_loss = 0.0\n",
    "    nb_eval_steps = 0\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "    model.eval()\n",
    "    device = \"cuda\"\n",
    "    examples = []\n",
    "    with torch.cuda.device(n_gpu):\n",
    "        for batch in test_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            with torch.no_grad():\n",
    "                inputs = {\"input_ids\": batch[0],\n",
    "                          \"attention_mask\": batch[1],\n",
    "                          \"token_type_ids\": batch[2],\n",
    "                          # XLM and RoBERTa don\"t use segment_ids\n",
    "                          \"labels\": batch[3]}\n",
    "                outputs = model(**inputs)\n",
    "                tmp_eval_loss, logits = outputs[:2]\n",
    "\n",
    "\n",
    "                eval_loss += tmp_eval_loss.item()\n",
    "            nb_eval_steps += 1\n",
    "            if preds is None:\n",
    "                preds = logits.detach().cpu().numpy()\n",
    "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "            examples.append(tokenizer.convert_ids_to_tokens([w for b in batch[0] for w in b.detach().cpu().numpy()]))\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        preds = np.argmax(preds, axis=2)\n",
    "\n",
    "        return eval_loss, preds, out_label_ids, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_f1(preds, truths):\n",
    "    filtered_preds = []\n",
    "    filtered_labels = []\n",
    "    for pred, labels in zip(preds, truths):\n",
    "        for pr, lab in zip(pred, labels):\n",
    "            if lab != -100:\n",
    "                filtered_preds.append(pr)\n",
    "                filtered_labels.append(lab)\n",
    "\n",
    "    return metrics.f1_score(filtered_preds, filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_precision(preds, truths):\n",
    "    filtered_preds = []\n",
    "    filtered_labels = []\n",
    "    for pred, labels in zip(preds, truths):\n",
    "        for pr, lab in zip(pred, labels):\n",
    "            if lab != -100:\n",
    "                filtered_preds.append(pr)\n",
    "                filtered_labels.append(lab)\n",
    "\n",
    "    return metrics.precision_score(filtered_preds, filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_recall(preds, truths):\n",
    "    filtered_preds = []\n",
    "    filtered_labels = []\n",
    "    for pred, labels in zip(preds, truths):\n",
    "        for pr, lab in zip(pred, labels):\n",
    "            if lab != -100:\n",
    "                filtered_preds.append(pr)\n",
    "                filtered_labels.append(lab)\n",
    "\n",
    "    return metrics.recall_score(filtered_preds, filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_accuracy(preds, truths):\n",
    "    filtered_preds = []\n",
    "    filtered_labels = []\n",
    "    for pred, labels in zip(preds, truths):\n",
    "        for pr, lab in zip(pred, labels):\n",
    "            if lab != -100:\n",
    "                filtered_preds.append(pr)\n",
    "                filtered_labels.append(lab)\n",
    "\n",
    "    return metrics.accuracy_score(filtered_preds, filtered_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, model, tokenizer, labels, pad_token_label_id, dev_dataloader, test_dataloader, train_batch_size=16, num_train_epochs=8, scheduler_type=\"linear\", lr=1e-5):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    \n",
    "    train_sampler = SequentialSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=lr, eps=1e-8, correct_bias=False)\n",
    "    if scheduler_type == \"linear\":\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=len(train_dataloader) * num_train_epochs * 0.1, num_training_steps=len(train_dataloader)*num_train_epochs)\n",
    "    else:\n",
    "        scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=len(train_dataloader) * num_train_epochs * 0.1)#, num_training_steps=t_total)\n",
    "#     scheduler = WarmupLinearSchedule(optimizer, warmup_steps=120, t_total=t_total)\n",
    "\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    train_loss_timeline = []\n",
    "    eval_loss_timeline = []\n",
    "    f1_timeline_dev = []\n",
    "#     f1_timeline_train = []\n",
    "    f1_timeline_test = []\n",
    "    precision_timeline_test = []\n",
    "    precision_timeline_dev = []\n",
    "    recall_timeline_test = []\n",
    "    recall_timeline_dev = []\n",
    "    accuracy_timeline_test = []\n",
    "    accuracy_timeline_dev = []\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(num_train_epochs), desc=\"Epoch\", disable=False)\n",
    "    w = open(\"{}_{}_{}_{}\".format(\"bert_large_uncased\", scheduler_type, lr, batch_size), 'w')\n",
    "    set_seed(42)  # Added here for reproductibility (even between python 2 and 3)\n",
    "    \n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=True)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {\"input_ids\": batch[0],\n",
    "                        \"attention_mask\": batch[1],\n",
    "                        \"token_type_ids\": batch[2],\n",
    "                        # XLM and RoBERTa don\"t use segment_ids\n",
    "                        \"labels\": batch[3]\n",
    "            }\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "            loss.backward()\n",
    "#             ipdb.set_trace()\n",
    "            tr_loss += loss.item()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            global_step += 1\n",
    "\n",
    "        # Evaluamos en dev\n",
    "        loss, preds, truth, examples = evaluate(model, dev_dataloader)\n",
    "        eval_loss_timeline.append(loss)\n",
    "        train_loss_timeline.append(tr_loss / global_step)\n",
    "        f1_timeline_dev.append(filtered_f1(preds, truth))\n",
    "        precision_timeline_dev.append(filtered_precision(preds, truth))\n",
    "        recall_timeline_dev.append(filtered_recall(preds,truth))\n",
    "        accuracy_timeline_dev.append(filtered_accuracy(preds, truth))\n",
    "        \n",
    "        # Evaluamos en test asi cuando sabemos el mejor epoch usando dev ya tenemos el resultado de test calculado\n",
    "        loss, preds, truth, examples = evaluate(model, test_dataloader)\n",
    "        f1_timeline_test.append(filtered_f1(preds, truth))\n",
    "        precision_timeline_test.append(filtered_precision(preds, truth))\n",
    "        recall_timeline_test.append(filtered_recall(preds,truth))\n",
    "        accuracy_timeline_test.append(filtered_accuracy(preds, truth))\n",
    "        # Evaluamos en train para ver si siempre da igual\n",
    "#         loss_tr_eval, preds_train, truth_train, examples_train = evaluate(model, train_dataloader)\n",
    "#         f1_timeline_train.append(filtered_f1(preds_train, truth_train))\n",
    "    tr_loss = 0\n",
    "    global_step = 0\n",
    "    \n",
    "    min_loss = eval_loss_timeline[0]\n",
    "    best_loss_epoch = 0\n",
    "    for epoch, losss in enumerate(eval_loss_timeline):\n",
    "        if losss < min_loss:\n",
    "            best_loss_epoch = epoch\n",
    "            \n",
    "    max_f1 = f1_timeline_dev[0]\n",
    "    best_f1_epoch = 0\n",
    "    for epoch, f11 in enumerate(f1_timeline_dev):\n",
    "        if f11 > max_f1:\n",
    "            best_f1_epoch = epoch    \n",
    "\n",
    "    w.write(\"USANDO LA LOSS:\\n\")\n",
    "    w.write(\"DEV\\n\")\n",
    "    w.write(\"{}\\n\".format(accuracy_timeline_dev[best_loss_epoch]))\n",
    "    w.write(\"{}\\n\".format(precision_timeline_dev[best_loss_epoch]))\n",
    "    w.write(\"{}\\n\".format(recall_timeline_dev[best_loss_epoch]))\n",
    "    w.write(\"{}\\n\".format(f1_timeline_dev[best_loss_epoch]))\n",
    "    w.write(\"\\n\")\n",
    "    w.write(\"TEST\\n\")\n",
    "    w.write(\"{}\\n\".format(accuracy_timeline_test[best_loss_epoch]))\n",
    "    w.write(\"{}\\n\".format(precision_timeline_test[best_loss_epoch]))\n",
    "    w.write(\"{}\\n\".format(recall_timeline_test[best_loss_epoch]))\n",
    "    w.write(\"{}\\n\".format(f1_timeline_test[best_loss_epoch]))\n",
    "    \n",
    "    w.write(\"USANDO F1:\\n\")\n",
    "    w.write(\"DEV\\n\")\n",
    "    w.write(\"{}\\n\".format(accuracy_timeline_dev[best_f1_epoch]))\n",
    "    w.write(\"{}\\n\".format(precision_timeline_dev[best_f1_epoch]))\n",
    "    w.write(\"{}\\n\".format(recall_timeline_dev[best_f1_epoch]))\n",
    "    w.write(\"{}\\n\".format(f1_timeline_dev[best_f1_epoch]))\n",
    "    w.write(\"\\n\")\n",
    "    w.write(\"TEST\\n\")\n",
    "    w.write(\"{}\\n\".format(accuracy_timeline_test[best_f1_epoch]))\n",
    "    w.write(\"{}\\n\".format(precision_timeline_test[best_f1_epoch]))\n",
    "    w.write(\"{}\\n\".format(recall_timeline_test[best_f1_epoch]))\n",
    "    w.write(\"{}\\n\".format(f1_timeline_test[best_f1_epoch]))\n",
    "    \n",
    "    w.close()\n",
    "    \n",
    "    return global_step, train_loss_timeline, eval_loss_timeline, f1_timeline_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Motion', 'is', 'one', 'of', 'the', 'most', 'important', 'ingredients', 'of', 'CG', 'movies', 'and', 'computer', 'games', '.']\n",
      "['claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'claim', 'O']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../train_mm.txt\", sep='\\t', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "#Sacarle las oraciones que empiezan con \"<\", el autor, abstract, etc\n",
    "\n",
    "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "num_labels = len(labels)\n",
    "\n",
    "examples = [InputExample(guid, words, labels) for guid, (words, labels) in enumerate(zip(sentences, labels))]\n",
    "print(examples[22].words)\n",
    "print(examples[22].labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 101\n",
      "[('[CLS]', 101, -100), ('each', 2169, 0), ('frame', 4853, 0), ('would', 2052, 0), ('be', 2022, 0), ('a', 1037, 0), ('node', 13045, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 102\n",
      "[('[CLS]', 101, -100), ('there', 2045, 0), ('would', 2052, 0), ('be', 2022, 0), ('an', 2019, 0), ('edge', 3341, 0), ('from', 2013, 0), ('every', 2296, 0), ('frame', 4853, 0), ('to', 2000, 0), ('every', 2296, 0), ('frame', 4853, 0), ('that', 2008, 0), ('could', 2071, 0), ('follow', 3582, 0), ('it', 2009, 0), ('in', 1999, 0), ('an', 2019, 0), ('acceptable', 11701, 0), ('sp', 11867, 0), ('##lice', 13231, -100), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 103\n",
      "[('[CLS]', 101, -100), ('in', 1999, 0), ('this', 2023, 0), ('graph', 10629, 0), (',', 1010, 0), ('there', 2045, 0), ('would', 2052, 0), ('be', 2022, 0), ('(', 1006, 0), ('at', 2012, 0), ('least', 2560, 0), (')', 1007, 0), ('an', 2019, 0), ('edge', 3341, 0), ('from', 2013, 0), ('the', 1996, 0), ('k', 1047, 0), ('a', 1037, 0), ('th', 16215, 0), ('frame', 4853, 0), ('to', 2000, 0), ('the', 1996, 0), ('k', 1047, 0), ('+', 1009, 0), ('1', 1015, 0), ('a', 1037, 0), ('th', 16215, 0), ('frame', 4853, 0), ('in', 1999, 0), ('each', 2169, 0), ('sequence', 5537, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 104\n",
      "[('[CLS]', 101, -100), ('this', 2023, 1), ('graph', 10629, 1), ('is', 2003, 1), ('not', 2025, 1), ('a', 1037, 1), ('particularly', 3391, 1), ('helpful', 14044, 1), ('representation', 6630, 1), ('because', 2138, 0), ('it', 2009, 0), ('is', 2003, 0), ('extremely', 5186, 0), ('large', 2312, 0), ('a', 1037, 0), ('we', 2057, 0), ('can', 2064, 0), ('easily', 4089, 0), ('have', 2031, 0), ('tens', 15295, 0), ('of', 1997, 0), ('thousands', 5190, 0), ('of', 1997, 0), ('nodes', 14164, 0), ('and', 1998, 0), ('hundreds', 5606, 0), ('of', 1997, 0), ('thousands', 5190, 0), ('of', 1997, 0), ('edges', 7926, 0), ('a', 1037, 0), ('and', 1998, 0), ('it', 2009, 0), ('obscure', 14485, 0), ('##s', 2015, -100), ('the', 1996, 0), ('structure', 3252, 0), ('of', 1997, 0), ('the', 1996, 0), ('sequences', 10071, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 105\n",
      "[('[CLS]', 101, -100), ('instead', 2612, 0), (',', 1010, 0), ('we', 2057, 0), ('collapse', 7859, 0), ('all', 2035, 0), ('the', 1996, 0), ('nodes', 14164, 0), ('(', 1006, 0), ('frames', 11048, 0), (')', 1007, 0), ('belonging', 7495, 0), ('to', 2000, 0), ('the', 1996, 0), ('same', 2168, 0), ('motion', 4367, 0), ('sequence', 5537, 0), ('together', 2362, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 106\n",
      "[('[CLS]', 101, -100), ('this', 2023, 0), ('yields', 16189, 0), ('a', 1037, 0), ('graph', 10629, 0), ('g', 1043, 0), ('where', 2073, 0), ('the', 1996, 0), ('nodes', 14164, 0), ('of', 1997, 0), ('g', 1043, 0), ('are', 2024, 0), ('individual', 3265, 0), ('motion', 4367, 0), ('sequences', 10071, 0), ('and', 1998, 0), ('there', 2045, 0), ('is', 2003, 0), ('an', 2019, 0), ('edge', 3341, 0), ('from', 2013, 0), ('s', 1055, 0), ('to', 2000, 0), ('t', 1056, 0), ('for', 2005, 0), ('every', 2296, 0), ('pair', 3940, 0), ('of', 1997, 0), ('frames', 11048, 0), ('where', 2073, 0), ('we', 2057, 0), ('can', 2064, 0), ('cut', 3013, 0), ('from', 2013, 0), ('s', 1055, 0), ('to', 2000, 0), ('t', 1056, 0), ('.', 1012, -100), ('since', 2144, 0), ('edges', 7926, 0), ('connect', 7532, 0), ('frames', 11048, 0), (',', 1010, 0), ('they', 2027, 1), ('are', 2024, 1), ('labelled', 18251, 1), ('with', 2007, 1), ('the', 1996, 1), ('frames', 11048, 1), ('[SEP]', 102, -100)]\n",
      "Example 107\n",
      "[('[CLS]', 101, -100), ('we', 2057, 0), ('also', 2036, 0), ('assume', 7868, 0), ('that', 2008, 0), ('the', 1996, 1), ('edges', 7926, 1), ('in', 1999, 1), ('g', 1043, 1), ('are', 2024, 1), ('attached', 4987, 1), ('a', 1037, 1), ('cost', 3465, 1), ('value', 3643, 1), ('which', 2029, 0), ('tells', 4136, 1), ('us', 2149, 1), ('the', 1996, 1), ('cost', 3465, 1), ('of', 1997, 1), ('connecting', 7176, 1), ('the', 1996, 1), ('incident', 5043, 1), ('frames', 11048, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 108\n",
      "[('[CLS]', 101, -100), ('if', 2065, 0), ('cutting', 6276, 0), ('from', 2013, 0), ('one', 2028, 0), ('sequence', 5537, 0), ('to', 2000, 0), ('another', 2178, 0), ('along', 2247, 0), ('an', 2019, 0), ('edge', 3341, 0), ('introduces', 13999, 0), ('a', 1037, 0), ('disco', 12532, 0), ('##nti', 16778, -100), ('##nu', 11231, -100), ('##ous', 3560, -100), ('motion', 4367, 0), (',', 1010, 0), ('then', 2059, 0), ('the', 1996, 1), ('cost', 3465, 1), ('attached', 4987, 1), ('to', 2000, 1), ('the', 1996, 1), ('edge', 3341, 1), ('is', 2003, 1), ('high', 2152, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 109\n",
      "[('[CLS]', 101, -100), ('appendix', 22524, 0), ('a', 1037, 0), ('introduces', 13999, 0), ('the', 1996, 0), ('cost', 3465, 0), ('function', 3853, 0), ('that', 2008, 0), ('we', 2057, 0), ('used', 2109, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 110\n",
      "[('[CLS]', 101, -100), ('the', 1996, 0), ('collapsed', 7798, 0), ('graph', 10629, 0), ('still', 2145, 0), ('has', 2038, 0), ('the', 1996, 0), ('same', 2168, 0), ('number', 2193, 0), ('of', 1997, 0), ('edges', 7926, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 111\n",
      "[('[CLS]', 101, -100), ('for', 2005, 0), ('an', 2019, 0), ('edge', 3341, 0), ('e', 1041, 0), ('from', 2013, 0), ('s', 1055, 0), ('i', 1045, 0), ('to', 2000, 0), ('t', 1056, 0), ('j', 1046, 0), (',', 1010, 0), ('let', 2292, 0), ('f', 1042, 0), ('rom', 17083, 0), ('##mot', 18938, -100), ('##ion', 3258, -100), ('(', 1006, 0), ('e', 1041, 0), (')', 1007, 0), ('=', 1027, 0), ('s', 1055, 0), (',', 1010, 0), ('tom', 3419, 0), ('##ot', 4140, -100), ('##ion', 3258, -100), ('(', 1006, 0), ('e', 1041, 0), (')', 1007, 0), ('=', 1027, 0), ('t', 1056, 0), (',', 1010, 0), ('f', 1042, 0), ('rom', 17083, 0), ('##frame', 15643, -100), ('(', 1006, 0), ('e', 1041, 0), (')', 1007, 0), ('=', 1027, 0), ('i', 1045, 0), (',', 1010, 0), ('to', 2000, 0), ('##frame', 15643, -100), ('(', 1006, 0), ('e', 1041, 0), (')', 1007, 0), ('=', 1027, 0), ('j', 1046, 0), ('and', 1998, 0), ('[SEP]', 102, -100)]\n",
      "Example 112\n",
      "[('[CLS]', 101, -100), ('in', 1999, 0), ('this', 2023, 0), ('setting', 4292, 0), (',', 1010, 0), ('any', 2151, 1), ('sequence', 5537, 1), ('of', 1997, 1), ('edges', 7926, 1), ('e', 1041, 1), ('1', 1015, 1), ('a', 1037, 1), ('·', 1087, -100), ('a', 1037, 1), ('·', 1087, -100), ('a', 1037, 1), ('·', 1087, -100), ('e', 1041, 1), ('n', 1050, 1), ('where', 2073, 0), ('tom', 3419, 0), ('##ot', 4140, -100), ('##ion', 3258, -100), ('(', 1006, 0), ('e', 1041, 0), ('i', 1045, 0), (')', 1007, 0), ('=', 1027, 0), ('f', 1042, 0), ('rom', 17083, 0), ('##mot', 18938, -100), ('##ion', 3258, -100), ('(', 1006, 0), ('e', 1041, 0), ('i', 1045, 0), ('+', 1009, -100), ('1', 1015, -100), (')', 1007, 0), ('and', 1998, 0), ('to', 2000, 0), ('##frame', 15643, -100), ('(', 1006, 0), ('e', 1041, 0), ('i', 1045, 0), (')', 1007, 0), ('&', 1004, 0), ('lt', 8318, 0), (';', 1025, 0), ('f', 1042, 0), ('[SEP]', 102, -100)]\n",
      "Example 113\n",
      "[('[CLS]', 101, -100), ('(', 1006, 0), ('figure', 3275, 0), ('1', 1015, 0), (')', 1007, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 114\n",
      "[('[CLS]', 101, -100), ('path', 4130, 0), ('edge', 3341, 0), ('1', 1015, 0), ('edge', 3341, 0), ('5', 1019, 0), ('edge', 3341, 0), ('2', 1016, 0), ('edge', 3341, 0), ('4', 1018, 0), ('edge', 3341, 0), ('3', 1017, 0), ('edge', 3341, 0), ('1', 1015, 0), ('sequences', 10071, 0), ('edge', 3341, 0), ('2', 1016, 0), ('edge', 3341, 0), ('4', 1018, 0), ('edge', 3341, 0), ('3', 1017, 0), ('motion', 4367, 0), ('edge', 3341, 0), ('5', 1019, 0), ('corresponding', 7978, 0), ('motion', 4367, 0), ('time', 2051, 0), ('[SEP]', 102, -100)]\n",
      "Example 115\n",
      "[('[CLS]', 101, -100), ('figure', 3275, 0), ('1', 1015, 0), (':', 1024, 0), ('we', 2057, 0), ('wish', 4299, 0), ('to', 2000, 0), ('synth', 24203, 0), ('##es', 2229, -100), ('##ize', 4697, -100), ('human', 2529, 0), ('motions', 15323, 0), ('by', 2011, 0), ('sp', 11867, 0), ('##lic', 10415, -100), ('##ing', 2075, -100), ('together', 2362, 0), ('pieces', 4109, 0), ('of', 1997, 0), ('existing', 4493, 0), ('motion', 4367, 0), ('capture', 5425, 0), ('data', 2951, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 116\n",
      "[('[CLS]', 101, -100), ('this', 2023, 0), ('can', 2064, 0), ('be', 2022, 0), ('done', 2589, 0), ('by', 2011, 0), ('representing', 5052, 0), ('the', 1996, 0), ('collection', 3074, 0), ('of', 1997, 0), ('motion', 4367, 0), ('sequences', 10071, 0), ('by', 2011, 0), ('a', 1037, 0), ('directed', 2856, 0), ('graph', 10629, 0), ('(', 1006, 0), ('top', 2327, 0), (')', 1007, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 117\n",
      "[('[CLS]', 101, -100), ('each', 2169, 0), ('sequence', 5537, 0), ('becomes', 4150, 0), ('a', 1037, 0), ('node', 13045, 0), (';', 1025, 0), ('there', 2045, 0), ('is', 2003, 0), ('an', 2019, 0), ('edge', 3341, 0), ('between', 2090, 0), ('nodes', 14164, 0), ('for', 2005, 0), ('every', 2296, 0), ('frame', 4853, 0), ('in', 1999, 0), ('one', 2028, 0), ('sequence', 5537, 0), ('that', 2008, 0), ('can', 2064, 0), ('be', 2022, 0), ('sp', 11867, 0), ('##lice', 13231, -100), ('##d', 2094, -100), ('to', 2000, 0), ('a', 1037, 0), ('frame', 4853, 0), ('in', 1999, 0), ('another', 2178, 0), ('sequence', 5537, 0), ('or', 2030, 0), ('itself', 2993, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 118\n",
      "[('[CLS]', 101, -100), ('a', 1037, 0), ('valid', 9398, 0), ('path', 4130, 0), ('in', 1999, 0), ('this', 2023, 0), ('graph', 10629, 0), ('represents', 5836, 0), ('a', 1037, 0), ('collection', 3074, 0), ('of', 1997, 0), ('sp', 11867, 0), ('##lices', 29146, -100), ('between', 2090, 0), ('sequences', 10071, 0), (',', 1010, 0), ('as', 2004, 0), ('the', 1996, 0), ('middle', 2690, 0), ('shows', 3065, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 119\n",
      "[('[CLS]', 101, -100), ('we', 2057, 0), ('now', 2085, 0), ('synth', 24203, 0), ('##es', 2229, -100), ('##ize', 4697, -100), ('constrained', 27570, 0), ('motion', 4367, 0), ('sequences', 10071, 0), ('by', 2011, 0), ('searching', 6575, 0), ('appropriate', 6413, 0), ('paths', 10425, 0), ('in', 1999, 0), ('this', 2023, 0), ('graph', 10629, 0), ('using', 2478, 0), ('a', 1037, 0), ('random', 6721, 0), ('##ized', 3550, -100), ('search', 3945, 0), ('method', 4118, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    possible_labels = [\"O\", \"claim\"]\n",
    "    features = convert_examples_to_features(examples, possible_labels, 50, tokenizer,\n",
    "                                                    cls_token_at_end=False,\n",
    "                                                    # xlnet has a cls token at the end\n",
    "                                                    cls_token=tokenizer.cls_token,\n",
    "                                                    cls_token_segment_id=0,\n",
    "                                                    sep_token=tokenizer.sep_token,\n",
    "                                                    sep_token_extra=False,\n",
    "                                                    # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "                                                    pad_on_left=False,\n",
    "                                                    # pad on the left for xlnet\n",
    "                                                    pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                                    pad_token_segment_id=0,\n",
    "                                                    pad_token_label_id=pad_token_label_id\n",
    "                                                    )\n",
    "\n",
    "\n",
    "        # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "\n",
    "    all_input_ids.to(device)\n",
    "    all_input_mask.to(device)\n",
    "    all_segment_ids.to(device)\n",
    "    all_label_ids.to(device)\n",
    "\n",
    "    train_dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devdata = pd.read_csv(\"../dev_mm.txt\", sep='\\t', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "\n",
    "getter = SentenceGetter(devdata)\n",
    "\n",
    "sentences_dev = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "labels_dev = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "num_labels = len(labels_dev)\n",
    "\n",
    "examples_dev = [InputExample(guid, words, labels) for guid, (words, labels) in enumerate(zip(sentences_dev, labels_dev))]\n",
    "\n",
    "len(examples_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 101\n",
      "[('[CLS]', 101, -100), ('2009', 2268, 0), (']', 1033, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 102\n",
      "[('[CLS]', 101, -100), ('has', 2038, 0), ('##e', 2063, -100), ('et', 3802, 0), ('al', 2632, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 103\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('2003', 2494, 0), (']', 1033, 0), ('[SEP]', 102, -100)]\n",
      "Example 104\n",
      "[('[CLS]', 101, -100), ('opt', 23569, 1), ('##imi', 27605, -100), ('##ze', 4371, -100), ('a', 1037, 1), ('cp', 18133, 1), ('##g', 2290, -100), ('-', 1011, -100), ('based', 2241, -100), ('(', 1006, 0), ('central', 2430, 0), ('pattern', 5418, 0), ('generator', 13103, 0), (')', 1007, 0), ('loco', 28046, 1), ('##mot', 18938, -100), ('##ion', 3258, -100), ('controller', 11486, 1), ('[', 1031, 0), ('tag', 6415, 0), ('##a', 2050, -100), ('1995', 2786, 0), (']', 1033, 0), ('for', 2005, 1), ('3d', 7605, 1), ('mu', 14163, 1), ('##scu', 28817, -100), ('##los', 10483, -100), ('##kel', 11705, -100), ('##eta', 12928, -100), ('##l', 2140, -100), ('models', 4275, 1), ('without', 2302, 1), ('tend', 7166, 1), ('##on', 2239, -100), ('or', 2030, 1), ('activation', 13791, 1), ('dynamics', 10949, 1), (',', 1010, 0), ('but', 2021, 0), ('their', 2037, 1), ('results', 3463, 1), ('were', 2020, 1), ('not', 2025, 1), ('compared', 4102, 1), ('to', 2000, 1), ('human', 2529, 1), ('kin', 12631, 1), ('##ema', 14545, -100), ('[SEP]', 102, -100)]\n",
      "Example 105\n",
      "[('[CLS]', 101, -100), ('moreover', 9308, 0), (',', 1010, 0), ('full', 2440, 1), ('mu', 14163, 1), ('##scu', 28817, -100), ('##los', 10483, -100), ('##kel', 11705, -100), ('##eta', 12928, -100), ('##l', 2140, -100), ('models', 4275, 1), ('are', 2024, 1), ('significantly', 6022, 1), ('more', 2062, 1), ('difficult', 3697, 1), ('to', 2000, 1), ('construct', 9570, 1), ('than', 2084, 1), ('joint', 4101, 1), ('-', 1011, -100), ('act', 2552, -100), ('##uated', 16453, -100), ('models', 4275, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 106\n",
      "[('[CLS]', 101, -100), ('our', 2256, 1), ('work', 2147, 1), ('demonstrates', 16691, 1), ('that', 2008, 1), ('me', 2033, 1), ('##asurable', 28329, -100), ('increase', 3623, 1), ('in', 1999, 1), ('loco', 28046, 1), ('##mot', 18938, -100), ('##ion', 3258, -100), ('realism', 15650, 1), ('can', 2064, 1), ('be', 2022, 1), ('produced', 2550, 1), ('by', 2011, 1), ('employing', 15440, 1), ('mu', 14163, 1), ('##scu', 28817, -100), ('##lot', 10994, -100), ('##end', 10497, -100), ('##on', 2239, -100), ('act', 2552, 1), ('##ua', 6692, -100), ('##tors', 6591, -100), ('for', 2005, 1), ('a', 1037, 1), ('small', 2235, 1), ('subset', 16745, 1), ('of', 1997, 1), ('the', 1996, 1), ('body', 2303, 1), ('do', 2079, 1), ('##fs', 10343, -100), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 107\n",
      "[('[CLS]', 101, -100), ('in', 1999, 1), ('the', 1996, 1), ('bio', 16012, 1), ('##me', 4168, -100), ('##chan', 14856, -100), ('##ics', 6558, -100), ('literature', 3906, 1), (',', 1010, 1), ('abstract', 10061, 1), ('plan', 2933, 1), ('##ar', 2906, -100), ('models', 4275, 1), ('have', 2031, 1), ('been', 2042, 1), ('used', 2109, 1), ('to', 2000, 1), ('study', 2817, 1), ('high', 2152, 1), ('-', 1011, -100), ('level', 2504, -100), ('principles', 6481, 1), ('of', 1997, 1), ('human', 2529, 1), ('loco', 28046, 1), ('##mot', 18938, -100), ('##ion', 3258, -100), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 108\n",
      "[('[CLS]', 101, -100), ('for', 2005, 0), ('example', 2742, 0), (',', 1010, 0), ('energy', 2943, 1), ('mini', 7163, 1), ('##mi', 4328, -100), ('##zation', 9276, -100), ('has', 2038, 1), ('been', 2042, 1), ('suggested', 4081, 1), ('as', 2004, 1), ('the', 1996, 1), ('criterion', 19229, 1), ('for', 2005, 1), ('humans', 4286, 1), ('in', 1999, 1), ('determining', 12515, 1), ('step', 3357, 1), ('length', 3091, 1), ('given', 2445, 1), ('walking', 3788, 1), ('speed', 3177, 1), ('[SEP]', 102, -100)]\n",
      "Example 109\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('ku', 13970, 0), ('##o', 2080, -100), ('2001', 2541, 0), (']', 1033, 0), (',', 1010, 0), ('as', 2004, 1), ('well', 2092, 1), ('as', 2004, 1), ('in', 1999, 1), ('selecting', 17739, 1), ('between', 2090, 1), ('walking', 3788, 1), ('and', 1998, 1), ('running', 2770, 1), ('[SEP]', 102, -100)]\n",
      "Example 110\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('sri', 5185, 0), ('##ni', 3490, -100), ('##vas', 12044, -100), ('##an', 2319, -100), ('and', 1998, 0), ('ruin', 10083, 0), ('##a', 2050, -100), ('2006', 2294, 0), (']', 1033, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 111\n",
      "[('[CLS]', 101, -100), ('the', 1996, 1), ('spring', 3500, 1), ('-', 1011, -100), ('loaded', 8209, -100), ('inverted', 20037, 1), ('pendulum', 28300, 1), ('(', 1006, 0), ('slip', 7540, 0), (')', 1007, 0), ('model', 2944, 1), ('[', 1031, 0), ('b', 1038, 0), ('##lick', 25230, -100), ('##han', 4819, -100), ('1989', 2960, 0), (']', 1033, 0), ('[SEP]', 102, -100)]\n",
      "Example 112\n",
      "[('[CLS]', 101, -100), ('has', 2038, 1), ('been', 2042, 1), ('used', 2109, 1), ('as', 2004, 1), ('a', 1037, 1), ('basis', 3978, 1), ('for', 2005, 1), ('predicting', 29458, 1), ('center', 2415, 1), ('-', 1011, -100), ('of', 1997, -100), ('-', 1011, -100), ('mass', 3742, -100), ('(', 1006, 0), ('com', 4012, 0), (')', 1007, 0), ('movements', 5750, 1), ('of', 1997, 1), ('human', 2529, 1), ('runners', 7190, 1), ('[', 1031, 0), ('full', 2440, 0), ('and', 1998, 0), ('ko', 12849, 0), ('##dit', 23194, -100), ('##sche', 22842, -100), ('##k', 2243, -100), ('1999', 2639, 0), (']', 1033, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 113\n",
      "[('[CLS]', 101, -100), ('however', 2174, 0), (',', 1010, 0), ('in', 1999, 1), ('the', 1996, 1), ('absence', 6438, 1), ('of', 1997, 1), ('knee', 6181, 1), ('joints', 17651, 1), (',', 1010, 1), ('these', 2122, 1), ('models', 4275, 1), ('can', 2064, 1), ('not', 2025, 1), ('be', 2022, 1), ('used', 2109, 1), ('to', 2000, 1), ('simulate', 26633, 1), ('accurate', 8321, 1), ('ga', 11721, 1), ('##it', 4183, -100), ('pat', 6986, 1), ('-', 1011, -100), ('ter', 28774, 1), ('##ns', 3619, -100), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 114\n",
      "[('[CLS]', 101, -100), ('using', 2478, 1), ('a', 1037, 1), ('2d', 14134, 1), ('model', 2944, 1), ('with', 2007, 1), ('knees', 5042, 1), ('and', 1998, 1), ('mu', 14163, 1), ('##scu', 28817, -100), ('##lot', 10994, -100), ('##end', 10497, -100), ('##on', 2239, -100), ('act', 2552, 1), ('##ua', 6692, -100), ('##tors', 6591, -100), (',', 1010, 0), ('[SEP]', 102, -100)]\n",
      "Example 115\n",
      "[('[CLS]', 101, -100), ('ge', 16216, 0), ('##yer', 10532, -100), ('and', 1998, 0), ('herr', 23506, 0), ('[', 1031, 0), ('2010', 2230, 0), (']', 1033, 0), ('[SEP]', 102, -100)]\n",
      "Example 116\n",
      "[('[CLS]', 101, -100), ('showed', 3662, 0), ('that', 2008, 0), ('patterns', 7060, 1), ('of', 1997, 1), ('human', 2529, 1), ('walking', 3788, 1), ('can', 2064, 1), ('be', 2022, 1), ('generated', 7013, 1), ('by', 2011, 1), ('a', 1037, 1), ('set', 2275, 1), ('of', 1997, 1), ('simple', 3722, 1), ('control', 2491, 1), ('laws', 4277, 1), ('motivated', 12774, 1), ('by', 2011, 1), ('muscle', 6740, 1), ('reflex', 22259, 1), ('##es', 2229, -100), (',', 1010, 0), ('which', 2029, 1), ('inspired', 4427, 1), ('our', 2256, 1), ('work', 2147, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 117\n",
      "[('[CLS]', 101, -100), ('we', 2057, 0), ('show', 2265, 0), ('how', 2129, 0), ('their', 2037, 1), ('basic', 3937, 1), ('ideas', 4784, 1), ('can', 2064, 1), ('be', 2022, 1), ('embedded', 11157, 1), ('in', 1999, 1), ('a', 1037, 1), ('3d', 7605, 1), ('humanoid', 28051, 1), ('model', 2944, 1), ('and', 1998, 1), ('extended', 3668, 1), ('to', 2000, 1), ('running', 2770, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 118\n",
      "[('[CLS]', 101, -100), ('similar', 2714, 1), ('2d', 14134, 1), ('models', 4275, 1), ('have', 2031, 1), ('been', 2042, 1), ('used', 2109, 1), ('for', 2005, 1), ('ga', 11721, 1), ('##it', 4183, -100), ('prediction', 17547, 1), ('[SEP]', 102, -100)]\n",
      "Example 119\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('ac', 9353, 0), ('##ker', 5484, -100), ('##mann', 5804, -100), ('and', 1998, 0), ('van', 3158, 0), ('den', 7939, 0), ('bog', 22132, 0), ('##ert', 8743, -100), ('2010', 2230, 0), (']', 1033, 0), (',', 1010, 0), ('and', 1998, 1), ('to', 2000, 1), ('generate', 9699, 1), ('human', 2529, 1), ('-', 1011, -100), ('like', 2066, -100), ('responses', 10960, 1), ('to', 2000, 1), ('disturbances', 24535, 1), ('[SEP]', 102, -100)]\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    device = \"cuda\"\n",
    "    possible_labels = [\"O\", \"claim\"]\n",
    "    features_dev = convert_examples_to_features(examples_dev, possible_labels, 50, tokenizer,\n",
    "                                                    cls_token_at_end=False,\n",
    "                                                    # xlnet has a cls token at the end\n",
    "                                                    cls_token=tokenizer.cls_token,\n",
    "                                                    cls_token_segment_id=0,\n",
    "                                                    sep_token=tokenizer.sep_token,\n",
    "                                                    sep_token_extra=False,\n",
    "                                                    # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "                                                    pad_on_left=False,\n",
    "                                                    # pad on the left for xlnet\n",
    "                                                    pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                                    pad_token_segment_id=0,\n",
    "                                                    pad_token_label_id=pad_token_label_id\n",
    "                                                    )\n",
    "\n",
    "        # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features_dev], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features_dev], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features_dev], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in features_dev], dtype=torch.long)\n",
    "    \n",
    "    all_input_ids.to(device)\n",
    "    all_input_mask.to(device)\n",
    "    all_segment_ids.to(device)\n",
    "    all_label_ids.to(device)\n",
    "\n",
    "    dev_dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    dev_sampler = SequentialSampler(dev_dataset)\n",
    "    dev_dataloader = DataLoader(dev_dataset, sampler=dev_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2944"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = pd.read_csv(\"../test_mm.txt\", sep='\\t', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "\n",
    "getter = SentenceGetter(testdata)\n",
    "\n",
    "sentences_test = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "labels_test = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "num_labels = len(labels_test)\n",
    "\n",
    "examples_test = [InputExample(guid, words, labels) for guid, (words, labels) in enumerate(zip(sentences_test, labels_test))]\n",
    "\n",
    "len(examples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 101\n",
      "[('[CLS]', 101, -100), ('using', 2478, 0), ('this', 2023, 0), ('vo', 29536, 0), ('##rno', 19139, -100), ('##i', 2072, -100), ('-', 1011, -100), ('based', 2241, -100), ('approach', 3921, 0), ('for', 2005, 0), ('te', 8915, 0), ('##tra', 6494, -100), ('##hedral', 27310, -100), ('mesh', 20437, 0), ('##es', 2229, -100), ('would', 2052, 0), ('yield', 10750, 0), ('a', 1037, 0), ('pressure', 3778, 0), ('matrix', 8185, 0), ('similar', 2714, 0), ('to', 2000, 0), ('ours', 14635, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 102\n",
      "[('[CLS]', 101, -100), ('like', 2066, 0), ('our', 2256, 0), ('method', 4118, 0), (',', 1010, 0), ('[SEP]', 102, -100)]\n",
      "Example 103\n",
      "[('[CLS]', 101, -100), ('bro', 22953, 0), ('##chu', 20760, -100), ('et', 3802, 0), ('al', 2632, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 104\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('2010', 2230, 0), (']', 1033, 0), ('[SEP]', 102, -100)]\n",
      "Example 105\n",
      "[('[CLS]', 101, -100), ('used', 2109, 1), ('this', 2023, 1), ('disc', 5860, 1), ('##ret', 13465, -100), ('##ization', 3989, -100), ('in', 1999, 1), ('combination', 5257, 1), ('with', 2007, 1), ('embedded', 11157, 1), ('second', 2117, 1), ('-', 1011, -100), ('order', 2344, -100), ('boundary', 6192, 1), ('conditions', 3785, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 106\n",
      "[('[CLS]', 101, -100), ('both', 2119, 0), ('of', 1997, 0), ('these', 2122, 0), ('approaches', 8107, 0), ('disc', 5860, 0), ('##ret', 13465, -100), ('##ize', 4697, -100), ('ve', 2310, 0), ('##lo', 4135, -100), ('##cit', 26243, -100), ('##ies', 3111, -100), ('with', 2007, 0), ('per', 2566, 0), ('-', 1011, -100), ('face', 2227, -100), ('flux', 19251, 0), ('values', 5300, 0), (',', 1010, 0), ('while', 2096, 0), ('we', 2057, 0), ('store', 3573, 0), ('velocity', 10146, 0), ('vectors', 19019, 0), ('at', 2012, 0), ('cell', 3526, 0), ('bar', 3347, 0), ('##yce', 29297, -100), ('##nte', 10111, -100), ('##rs', 2869, -100), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 107\n",
      "[('[CLS]', 101, -100), ('adaptive', 19293, 1), ('simulations', 24710, 1), ('have', 2031, 1), ('also', 2036, 1), ('been', 2042, 1), ('explored', 10641, 1), ('in', 1999, 1), ('the', 1996, 1), ('context', 6123, 1), ('of', 1997, 1), ('sp', 11867, 1), ('##h', 2232, -100), ('simulations', 24710, 1), ('without', 2302, 1), ('eu', 7327, 1), ('##ler', 3917, -100), ('##ian', 2937, -100), ('grid', 8370, 1), ('##s', 2015, -100), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 108\n",
      "[('[CLS]', 101, -100), ('the', 1996, 0), ('work', 2147, 0), ('of', 1997, 0), ('[SEP]', 102, -100)]\n",
      "Example 109\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('adams', 5922, 0), ('et', 3802, 0), ('al', 2632, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 110\n",
      "[('[CLS]', 101, -100), ('2007', 2289, 0), (']', 1033, 0), ('[SEP]', 102, -100)]\n",
      "Example 111\n",
      "[('[CLS]', 101, -100), ('shares', 6661, 1), ('similarities', 12319, 1), ('with', 2007, 1), ('our', 2256, 1), ('approach', 3921, 1), (',', 1010, 0), ('as', 2004, 0), ('it', 2009, 1), ('is', 2003, 1), ('able', 2583, 1), ('to', 2000, 1), ('simulate', 26633, 1), ('a', 1037, 1), ('wider', 7289, 1), ('range', 2846, 1), ('of', 1997, 1), ('particle', 10811, 1), ('ra', 10958, 1), ('##di', 4305, -100), ('##i', 2072, -100), (',', 1010, 0), ('and', 1998, 0), ('it', 2009, 1), ('proposes', 17146, 1), ('a', 1037, 1), ('surface', 3302, 1), ('reconstruction', 8735, 1), ('method', 4118, 1), ('in', 1999, 1), ('the', 1996, 1), ('adaptive', 19293, 1), ('setting', 4292, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 112\n",
      "[('[CLS]', 101, -100), ('we', 2057, 0), ('will', 2097, 0), ('show', 2265, 0), ('in', 1999, 0), ('section', 2930, 0), ('5', 1019, 0), ('that', 2008, 0), ('our', 2256, 0), ('surface', 3302, 0), ('creation', 4325, 0), ('method', 4118, 0), ('results', 3463, 0), ('in', 1999, 0), ('surfaces', 9972, 0), ('with', 2007, 0), ('fewer', 8491, 0), ('visual', 5107, 0), ('artifacts', 10471, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 113\n",
      "[('[CLS]', 101, -100), ('additionally', 5678, 0), (',', 1010, 0), ('a', 1037, 1), ('robust', 15873, 1), ('and', 1998, 1), ('efficient', 8114, 1), ('method', 4118, 1), ('for', 2005, 1), ('adaptive', 19293, 1), ('sp', 11867, 1), ('##h', 2232, -100), ('simulations', 24710, 1), ('was', 2001, 1), ('introduced', 3107, 1), ('by', 2011, 1), ('[SEP]', 102, -100)]\n",
      "Example 114\n",
      "[('[CLS]', 101, -100), ('sole', 7082, 0), ('##nt', 3372, -100), ('##hale', 15238, -100), ('##r', 2099, -100), ('et', 3802, 0), ('al', 2632, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 115\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('2011', 2249, 0), (']', 1033, 0), ('[SEP]', 102, -100)]\n",
      "Example 116\n",
      "[('[CLS]', 101, -100), (',', 1010, 0), ('but', 2021, 0), ('this', 2023, 1), ('work', 2147, 1), ('primarily', 3952, 1), ('targets', 7889, 1), ('the', 1996, 1), ('coupling', 19780, 1), ('of', 1997, 1), ('two', 2048, 1), ('different', 2367, 1), ('particle', 10811, 1), ('resolutions', 18853, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 117\n",
      "[('[CLS]', 101, -100), ('several', 2195, 1), ('other', 2060, 1), ('methods', 4725, 1), ('have', 2031, 1), ('been', 2042, 1), ('proposed', 3818, 1), ('to', 2000, 1), ('rec', 28667, 1), ('##ons', 5644, -100), ('##truct', 18300, -100), ('smooth', 5744, 1), ('surfaces', 9972, 1), ('around', 2105, 1), ('collections', 6407, 1), ('of', 1997, 1), ('particles', 9309, 1), ('without', 2302, 1), ('orientation', 10296, 1), ('.', 1012, 0), ('[SEP]', 102, -100)]\n",
      "Example 118\n",
      "[('[CLS]', 101, -100), ('one', 2028, 1), ('approach', 3921, 1), ('that', 2008, 1), ('is', 2003, 1), ('commonly', 4141, 1), ('used', 2109, 1), ('is', 2003, 1), ('to', 2000, 1), ('compute', 24134, 1), ('a', 1037, 1), ('signed', 2772, 1), ('distance', 3292, 1), ('function', 3853, 1), ('with', 2007, 1), ('averaged', 11398, 1), ('particle', 10811, 1), ('ra', 10958, 1), ('##di', 4305, -100), ('##i', 2072, -100), ('and', 1998, 1), ('centro', 18120, 1), ('##ids', 9821, -100), ('[SEP]', 102, -100)]\n",
      "Example 119\n",
      "[('[CLS]', 101, -100), ('[', 1031, 0), ('zhu', 15503, 0), ('and', 1998, 0), ('br', 7987, 0), ('##ids', 9821, -100), ('##on', 2239, -100), ('2005', 2384, 0), (']', 1033, 0), ('.', 1012, 0), ('[SEP]', 102, -100)]\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    device = \"cuda\"\n",
    "    possible_labels = [\"O\", \"claim\"]\n",
    "    features_test = convert_examples_to_features(examples_test, possible_labels, 50, tokenizer,\n",
    "                                                    cls_token_at_end=False,\n",
    "                                                    # xlnet has a cls token at the end\n",
    "                                                    cls_token=tokenizer.cls_token,\n",
    "                                                    cls_token_segment_id=0,\n",
    "                                                    sep_token=tokenizer.sep_token,\n",
    "                                                    sep_token_extra=False,\n",
    "                                                    # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "                                                    pad_on_left=False,\n",
    "                                                    # pad on the left for xlnet\n",
    "                                                    pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                                    pad_token_segment_id=0,\n",
    "                                                    pad_token_label_id=pad_token_label_id\n",
    "                                                    )\n",
    "\n",
    "        # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features_test], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features_test], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features_test], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in features_test], dtype=torch.long)\n",
    "    \n",
    "    all_input_ids.to(device)\n",
    "    all_input_mask.to(device)\n",
    "    all_segment_ids.to(device)\n",
    "    all_label_ids.to(device)\n",
    "\n",
    "    test_dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0306 13:36:13.823281 140305489397504 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0306 13:36:24.125788 140305489397504 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0306 13:36:24.126874 140305489397504 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 8/8 [54:42<00:00, 411.22s/it]\n",
      "I0306 14:31:07.036275 140305489397504 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-8epochs-linear_1e-05_24/config.json\n",
      "I0306 14:31:07.847331 140305489397504 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-8epochs-linear_1e-05_24/pytorch_model.bin\n",
      "I0306 14:31:08.560710 140305489397504 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0306 14:31:18.346023 140305489397504 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0306 14:31:18.347095 140305489397504 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 8/8 [55:00<00:00, 412.06s/it]\n",
      "I0306 15:26:19.000007 140305489397504 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-8epochs-linear_2e-05_24/config.json\n",
      "I0306 15:26:19.807779 140305489397504 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-8epochs-linear_2e-05_24/pytorch_model.bin\n",
      "I0306 15:26:20.668853 140305489397504 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0306 15:26:30.294260 140305489397504 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0306 15:26:30.295389 140305489397504 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 8/8 [55:02<00:00, 413.18s/it]\n",
      "I0306 16:21:32.591973 140305489397504 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-8epochs-linear_5e-06_24/config.json\n",
      "I0306 16:21:33.395494 140305489397504 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-8epochs-linear_5e-06_24/pytorch_model.bin\n",
      "I0306 16:21:34.130097 140305489397504 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0306 16:21:44.110094 140305489397504 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0306 16:21:44.111163 140305489397504 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 8/8 [55:16<00:00, 413.17s/it]\n",
      "I0306 17:17:00.893422 140305489397504 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-8epochs-constant_1e-05_24/config.json\n",
      "I0306 17:17:01.697915 140305489397504 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-8epochs-constant_1e-05_24/pytorch_model.bin\n",
      "I0306 17:17:02.462004 140305489397504 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0306 17:17:11.786836 140305489397504 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0306 17:17:11.787937 140305489397504 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 8/8 [54:57<00:00, 412.00s/it]\n",
      "I0306 18:12:09.602073 140305489397504 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-8epochs-constant_2e-05_24/config.json\n",
      "I0306 18:12:10.405220 140305489397504 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-8epochs-constant_2e-05_24/pytorch_model.bin\n",
      "I0306 18:12:11.140196 140305489397504 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0306 18:12:20.946752 140305489397504 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0306 18:12:20.947873 140305489397504 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 8/8 [54:56<00:00, 412.10s/it]\n",
      "I0306 19:07:17.435080 140305489397504 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-8epochs-constant_5e-06_24/config.json\n",
      "I0306 19:07:18.224842 140305489397504 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-8epochs-constant_5e-06_24/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    for sched in [\"linear\",\"constant\"]:\n",
    "        for lr in [1e-5, 2e-5, 5e-6]:\n",
    "            for batch_size in [24]:\n",
    "                model = model_class.from_pretrained(bert_type, from_tf=False, config=config)\n",
    "                model.to(device)\n",
    "                global_step, train_loss_timeline, dev_loss_timeline, f1_timeline = train(train_dataset, model, tokenizer, labels, pad_token_label_id, dev_dataloader, test_dataloader, scheduler_type=sched, lr=lr, train_batch_size=batch_size)\n",
    "                if not os.path.exists(\"../pretrained-models/bert-large-uncased-8epochs-{}_{}_{}\".format(sched, str(lr), str(batch_size))):\n",
    "                    os.mkdir(\"../pretrained-models/bert-large-uncased-8epochs-{}_{}_{}\".format(sched, str(lr), str(batch_size)))\n",
    "                model.save_pretrained(\"../pretrained-models/bert-large-uncased-8epochs-{}_{}_{}\".format(sched, str(lr), str(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f58d63b1390>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(f1_timeline)), f1_timeline, label=\"f1\")\n",
    "ax.plot(np.arange(len(f1_timeline_train)), f1_timeline_train, label=\"f1\")\n",
    "ax.plot(np.arange(len(train_loss_timeline)), train_loss_timeline, label=\"train\")\n",
    "ax.plot(np.arange(len(dev_loss_timeline)), dev_loss_timeline, label=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7997313429602105,\n",
       " 0.7997313429602105,\n",
       " 0.7997313429602105,\n",
       " 0.7997313429602105,\n",
       " 0.7997313429602105]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_timeline_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0218 09:07:57.898455 140025004766976 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0218 09:08:08.360332 140025004766976 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0218 09:08:08.361425 140025004766976 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 5/5 [1:09:32<00:00, 834.55s/it]\n",
      "I0218 10:17:40.885926 140025004766976 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-5epochs-1e-5_linear_schedule_x2/config.json\n",
      "I0218 10:17:41.750609 140025004766976 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-5epochs-1e-5_linear_schedule_x2/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    model = model_class.from_pretrained(bert_type, from_tf=False, config=config)\n",
    "    model.to(device)\n",
    "    global_step, train_loss_timeline, dev_loss_timeline, f1_timeline, f1_timeline_train = train(train_dataset, model, tokenizer, labels, pad_token_label_id, dev_dataloader, 5, 5, \"linear\", len(dev_dataloader)*2)\n",
    "    model.save_pretrained(\"../pretrained-models/bert-large-uncased-5epochs-1e-5_linear_schedule_x2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f58d58d3d30>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(f1_timeline)), f1_timeline, label=\"f1\")\n",
    "ax.plot(np.arange(len(f1_timeline_train)), f1_timeline_train, label=\"f1\")\n",
    "ax.plot(np.arange(len(train_loss_timeline)), train_loss_timeline, label=\"train\")\n",
    "ax.plot(np.arange(len(dev_loss_timeline)), dev_loss_timeline, label=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7700408163265307,\n",
       " 0.7899424184261036,\n",
       " 0.7899424184261036,\n",
       " 0.7899424184261036,\n",
       " 0.7899424184261036]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0218 14:31:14.359904 140025004766976 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "Epoch: 100%|██████████| 5/5 [1:09:18<00:00, 831.49s/it]\n",
      "I0218 15:40:43.891940 140025004766976 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-5epochs-1e-5_linear_schedule_x4/config.json\n",
      "I0218 15:40:44.707392 140025004766976 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-5epochs-1e-5_linear_schedule_x4/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    model = model_class.from_pretrained(bert_type, from_tf=False, config=config)\n",
    "    model.to(device)\n",
    "    global_step, train_loss_timeline, dev_loss_timeline, f1_timeline, f1_timeline_train = train(train_dataset, model, tokenizer, labels, pad_token_label_id, dev_dataloader, 5, 5, \"linear\", len(dev_dataloader)*4)\n",
    "    model.save_pretrained(\"../pretrained-models/bert-large-uncased-5epochs-1e-5_linear_schedule_x4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f58d7dd4b38>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(f1_timeline)), f1_timeline, label=\"f1\")\n",
    "ax.plot(np.arange(len(f1_timeline_train)), f1_timeline_train, label=\"f1\")\n",
    "ax.plot(np.arange(len(train_loss_timeline)), train_loss_timeline, label=\"train\")\n",
    "ax.plot(np.arange(len(dev_loss_timeline)), dev_loss_timeline, label=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.804206760424377,\n",
       " 0.8699473071031917,\n",
       " 0.904564167453797,\n",
       " 0.9080720401535283,\n",
       " 0.9080720401535283]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_timeline_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16611"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0221 21:17:09.499602 139700597274368 modeling_utils.py:406] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I0221 21:17:19.540846 139700597274368 modeling_utils.py:480] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I0221 21:17:19.541937 139700597274368 modeling_utils.py:483] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch: 100%|██████████| 2/2 [16:23<00:00, 491.78s/it]\n",
      "I0221 21:33:43.499181 139700597274368 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-2epochs-1e-5_constant_schedule_proportional/config.json\n",
      "I0221 21:33:47.260741 139700597274368 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-2epochs-1e-5_constant_schedule_proportional/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    model = model_class.from_pretrained(bert_type, from_tf=False, config=config)\n",
    "    model.to(device)\n",
    "    global_step, train_loss_timeline, dev_loss_timeline, f1_timeline, f1_timeline_train = train(train_dataset, model, tokenizer, labels, pad_token_label_id, dev_dataloader, num_train_epochs=2, scheduler_type=\"constant\")\n",
    "model.save_pretrained(\"../pretrained-models/bert-large-uncased-2epochs-1e-5_constant_schedule_proportional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0d9c73c5c0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(f1_timeline)), f1_timeline, label=\"f1\")\n",
    "ax.plot(np.arange(len(f1_timeline_train)), f1_timeline_train, label=\"f1\")\n",
    "ax.plot(np.arange(len(train_loss_timeline)), train_loss_timeline, label=\"train\")\n",
    "ax.plot(np.arange(len(dev_loss_timeline)), dev_loss_timeline, label=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7794123151787387, 0.7758564702062023]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0226 00:28:52.636839 139756314355456 configuration_utils.py:182] loading configuration file ../pretrained-models/bert-large-uncased-2epochs-1e-5_constant_schedule_proportional/config.json\n",
      "I0226 00:28:52.638084 139756314355456 configuration_utils.py:199] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0226 00:28:52.639038 139756314355456 modeling_utils.py:403] loading weights file ../pretrained-models/bert-large-uncased-2epochs-1e-5_constant_schedule_proportional/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"../pretrained-models/bert-large-uncased-2epochs-1e-5_constant_schedule_proportional\")\n",
    "with torch.cuda.device(1):\n",
    "    model.to(\"cuda\")\n",
    "    eval_loss, preds, out_label_ids, examples = evaluate(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2572"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds = []\n",
    "filtered_labels = []\n",
    "for pred, labels in zip(preds, out_label_ids):\n",
    "    for pr, lab in zip(pred, labels):\n",
    "        if lab != -100:\n",
    "            filtered_preds.append(pr)\n",
    "            filtered_labels.append(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7147352496217851"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_f1(preds, out_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0210 15:16:27.283423 140657494583040 configuration_utils.py:87] Configuration saved in ../pretrained-models/bert-large-uncased-5epochs-1e-5/config.json\n",
      "I0210 15:16:28.130554 140657494583040 modeling_utils.py:258] Model weights saved in ../pretrained-models/bert-large-uncased-5epochs-1e-5/pytorch_model.bin\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
