{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1104 15:55:43.196853 140440240211712 file_utils.py:39] PyTorch version 1.2.0 available.\n",
      "I1104 15:55:43.426519 140440240211712 modeling_xlnet.py:194] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import AdamW, WarmupLinearSchedule\n",
    "from transformers import WEIGHTS_NAME, BertConfig, BertForTokenClassification, BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from io import open\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"bert\": (BertConfig, BertForTokenClassification, BertTokenizer),\n",
    "}\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for token classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, words, labels):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            words: list. The words of the sequence.\n",
    "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.words = words\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"text\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\"\n",
    "n_gpu = 0\n",
    "\n",
    "# Set seed\n",
    "set_seed(42)\n",
    "\n",
    "data = pd.read_csv(\"../train.txt\", sep='\\t', encoding=\"latin1\").fillna(method=\"ffill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('<', 'O'),\n",
       "  ('?', 'O'),\n",
       "  ('xml', 'O'),\n",
       "  ('version=', 'O'),\n",
       "  ('\\t_\\t_\\tO\\t0\\n5\\t1.0\\t_\\t_\\tO\\t0\\n6\\t', 'O'),\n",
       "  ('encoding=', 'O'),\n",
       "  ('\\t_\\t_\\tO\\t0\\n9\\tUTF-8\\t_\\t_\\tO\\t0\\n10\\t', 'O'),\n",
       "  ('standalone=', 'O'),\n",
       "  ('\\t_\\t_\\tO\\t0\\n13\\tno\\t_\\t_\\tO\\t0\\n14\\t', 'O'),\n",
       "  ('?', 'O'),\n",
       "  ('>', 'O')],\n",
       " [('<', 'O'),\n",
       "  ('Document', 'O'),\n",
       "  ('xmlns', 'O'),\n",
       "  (':', 'O'),\n",
       "  ('gate=', 'O'),\n",
       "  ('\\t_\\t_\\tO\\t1\\n23\\thttp\\t_\\t_\\tO\\t1\\n24\\t:\\t_\\t_\\tO\\t1\\n25\\t//www.gate.ac.uk\\t_\\t_\\tO\\t1\\n26\\t',\n",
       "   'O'),\n",
       "  ('name=', 'O'),\n",
       "  ('\\t_\\t_\\tO\\t1\\n29\\tA15_M06_Interactive_Motion_Generation_from_Examples_CITATION_PURPOSE_M_v1.xml\\t_\\t_\\tO\\t1\\n30\\t',\n",
       "   'O'),\n",
       "  ('>', 'O')]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getter = SentenceGetter(data)\n",
    "\n",
    "getter.sentences[:2]\n",
    "#Sacarle las oraciones que empiezan con \"<\", el autor, abstract, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['They', 'are', 'generated', 'in', 'real', 'time', 'so', 'that', 'we', 'can', 'author', 'complex', 'motions', 'interactively', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "examples = [InputExample(guid, words, labels) for guid, (words, labels) in enumerate(zip(sentences, labels))]\n",
    "print(examples[15].words)\n",
    "print(examples[15].labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1104 15:55:56.999062 140440240211712 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /home/dfurman/.cache/torch/transformers/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.4c88e2dec8f8b017f319f6db2b157fee632c0860d9422e4851bd0d6999f9ce38\n",
      "I1104 15:55:57.001684 140440240211712 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_labels\": 16611,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I1104 15:55:57.680703 140440240211712 tokenization_utils.py:374] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /home/dfurman/.cache/torch/transformers/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I1104 15:55:58.494747 140440240211712 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /home/dfurman/.cache/torch/transformers/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
      "I1104 15:56:06.451244 140440240211712 modeling_utils.py:405] Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1104 15:56:06.452306 140440240211712 modeling_utils.py:408] Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    # Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later\n",
    "    pad_token_label_id = CrossEntropyLoss().ignore_index\n",
    "\n",
    "    model_type = \"bert\"\n",
    "    config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "\n",
    "    bert_type = \"bert-large-uncased\"\n",
    "    config = config_class.from_pretrained(bert_type,\n",
    "                                              num_labels=num_labels)\n",
    "    tokenizer = tokenizer_class.from_pretrained(bert_type,\n",
    "                                                    do_lower_case=True)\n",
    "    model = model_class.from_pretrained(bert_type, from_tf=False,\n",
    "                                            config=config)\n",
    "    model.to(device)\n",
    "\n",
    "    'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, model, tokenizer, labels, pad_token_label_id):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    \n",
    "    train_batch_size = 4\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=train_batch_size)\n",
    "\n",
    "    num_train_epochs = 5.0\n",
    "    t_total = len(train_dataloader) // num_train_epochs\n",
    "\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "         \"weight_decay\": 0.1},\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=5e-5, eps=1e-8)\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=0, t_total=t_total)\n",
    "\n",
    "    # Train!\n",
    "#     print(\"***** Running training *****\")\n",
    "#     print(\"  Num examples = %d\", len(train_dataset))\n",
    "#     print(\"  Num Epochs = %d\", num_train_epochs)\n",
    "#     print(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "    global_step = 0\n",
    "    tr_loss, logging_loss = 0.0, 0.0\n",
    "    model.zero_grad()\n",
    "    train_iterator = trange(int(num_train_epochs), desc=\"Epoch\", disable=False)\n",
    "    set_seed(42)  # Added here for reproductibility (even between python 2 and 3)\n",
    "    for _ in train_iterator:\n",
    "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=False)\n",
    "        for step, batch in enumerate(epoch_iterator):\n",
    "            model.train()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs = {\"input_ids\": batch[0],\n",
    "                        \"attention_mask\": batch[1],\n",
    "                        \"token_type_ids\": batch[2],\n",
    "                        # XLM and RoBERTa don\"t use segment_ids\n",
    "                        \"labels\": batch[3]\n",
    "            }\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n",
    "            loss.backwards()\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "    return global_step, tr_loss / global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_cache_examples(tokenizer, labels, pad_token_label_id, mode):\n",
    "\n",
    "#     # Load data features from cache or dataset file\n",
    "#     cached_features_file = \"cached_{}_{}_{}\".format(mode, \"bert-large-cased\", 300)\n",
    "\n",
    "#     logger.info(\"Creating features from dataset file\")\n",
    "#     features = convert_examples_to_features(examples, labels, 300, tokenizer,\n",
    "#                                                 cls_token_at_end=False,\n",
    "#                                                 # xlnet has a cls token at the end\n",
    "#                                                 cls_token=tokenizer.cls_token,\n",
    "#                                                 cls_token_segment_id=0,\n",
    "#                                                 sep_token=tokenizer.sep_token,\n",
    "#                                                 sep_token_extra=False,\n",
    "#                                                 # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "#                                                 pad_on_left=False,\n",
    "#                                                 # pad on the left for xlnet\n",
    "#                                                 pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "#                                                 pad_token_segment_id=0,\n",
    "#                                                 pad_token_label_id=pad_token_label_id\n",
    "#                                                 )\n",
    "#     torch.save(features, cached_features_file)\n",
    "\n",
    "\n",
    "#     # Convert to Tensors and build dataset\n",
    "#     all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "#     all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "#     all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "#     all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "\n",
    "#     dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_examples_from_file(data_dir, mode):\n",
    "#     file_path = \"../{}.txt\".format(mode)\n",
    "#     guid_index = 1\n",
    "#     examples = []\n",
    "#     with open(file_path, encoding=\"utf-8\") as f:\n",
    "#         words = []\n",
    "#         labels = []\n",
    "#         for line in f:\n",
    "#             if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\":\n",
    "#                 if words:\n",
    "#                     examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index),\n",
    "#                                                  words=words,\n",
    "#                                                  labels=labels))\n",
    "#                     guid_index += 1\n",
    "#                     words = []\n",
    "#                     labels = []\n",
    "#             else:\n",
    "#                 splits = line.split(\" \")\n",
    "#                 words.append(splits[0])\n",
    "#                 if len(splits) > 1:\n",
    "#                     labels.append(splits[-1].replace(\"\\n\", \"\"))\n",
    "#                 else:\n",
    "#                     # Examples could have no label for mode = \"test\"\n",
    "#                     labels.append(\"O\")\n",
    "#         if words:\n",
    "#             examples.append(InputExample(guid=\"%s-%d\".format(mode, guid_index),\n",
    "#                                          words=words,\n",
    "#                                          labels=labels))\n",
    "#     return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples,\n",
    "                                 label_list,\n",
    "                                 max_seq_length,\n",
    "                                 tokenizer,\n",
    "                                 cls_token_at_end=False,\n",
    "                                 cls_token=\"[CLS]\",\n",
    "                                 cls_token_segment_id=1,\n",
    "                                 sep_token=\"[SEP]\",\n",
    "                                 sep_token_extra=False,\n",
    "                                 pad_on_left=False,\n",
    "                                 pad_token=0,\n",
    "                                 pad_token_segment_id=0,\n",
    "                                 pad_token_label_id=-1,\n",
    "                                 sequence_a_segment_id=0,\n",
    "                                 mask_padding_with_zero=True):\n",
    "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
    "        `cls_token_at_end` define the location of the CLS token:\n",
    "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
    "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
    "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
    "    \"\"\"\n",
    "\n",
    "    label_map = {label: i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "#         if ex_index % 10000 == 0:\n",
    "#             print(\"Writing example {} of {}\".format(ex_index, len(examples)))\n",
    "#             print(\"E.g: {}\".format(example.words))\n",
    "\n",
    "        tokens = []\n",
    "        label_ids = []\n",
    "        for word, label in zip(example.words, example.labels):\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            tokens.extend(word_tokens)\n",
    "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
    "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
    "\n",
    "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
    "        special_tokens_count = 3 if sep_token_extra else 2\n",
    "        if len(tokens) > max_seq_length - special_tokens_count:\n",
    "            tokens = tokens[:(max_seq_length - special_tokens_count)]\n",
    "            label_ids = label_ids[:(max_seq_length - special_tokens_count)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids:   0   0   0   0  0     0   0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens += [sep_token]\n",
    "        label_ids += [pad_token_label_id]\n",
    "        if sep_token_extra:\n",
    "            # roberta uses an extra separator b/w pairs of sentences\n",
    "            tokens += [sep_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
    "\n",
    "        if cls_token_at_end:\n",
    "            tokens += [cls_token]\n",
    "            label_ids += [pad_token_label_id]\n",
    "            segment_ids += [cls_token_segment_id]\n",
    "        else:\n",
    "            tokens = [cls_token] + tokens\n",
    "            label_ids = [pad_token_label_id] + label_ids\n",
    "            segment_ids = [cls_token_segment_id] + segment_ids\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if pad_on_left:\n",
    "            input_ids = ([pad_token] * padding_length) + input_ids\n",
    "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
    "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
    "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
    "        else:\n",
    "            input_ids += ([pad_token] * padding_length)\n",
    "            input_mask += ([0 if mask_padding_with_zero else 1] * padding_length)\n",
    "            segment_ids += ([pad_token_segment_id] * padding_length)\n",
    "            label_ids += ([pad_token_label_id] * padding_length)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        assert len(label_ids) == max_seq_length\n",
    "\n",
    "#         if ex_index > 10 and ex_index < 12:\n",
    "#             print(\"*** Example ***\")\n",
    "#             print(\"guid: %s\", example.guid)\n",
    "#             print(\"tokens: %s\", \" \".join([str(x) for x in tokens]))\n",
    "#             print(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
    "#             print(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
    "#             print(\"segment_ids: %s\", \" \".join([str(x) for x in segment_ids]))\n",
    "#             print(\"label_ids: %s\", \" \".join([str(x) for x in label_ids]))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_ids=label_ids))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(n_gpu):\n",
    "    possible_labels = [\"O\", \"B-claim\", \"I-claim\"]\n",
    "    features = convert_examples_to_features(examples, possible_labels, 50, tokenizer,\n",
    "                                                    cls_token_at_end=False,\n",
    "                                                    # xlnet has a cls token at the end\n",
    "                                                    cls_token=tokenizer.cls_token,\n",
    "                                                    cls_token_segment_id=0,\n",
    "                                                    sep_token=tokenizer.sep_token,\n",
    "                                                    sep_token_extra=False,\n",
    "                                                    # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "                                                    pad_on_left=False,\n",
    "                                                    # pad on the left for xlnet\n",
    "                                                    pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                                    pad_token_segment_id=0,\n",
    "                                                    pad_token_label_id=pad_token_label_id\n",
    "                                                    )\n",
    "\n",
    "\n",
    "        # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/4153 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'backwards'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3a41c3fa985f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train_dataset = load_and_cache_examples(tokenizer, labels, pad_token_label_id, mode=\"train\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_label_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" global_step = %s, average loss = %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-09fcd5845a02>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataset, model, tokenizer, labels, pad_token_label_id)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# model outputs are always tuple in pytorch-transformers (see doc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update learning rate schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'backwards'"
     ]
    }
   ],
   "source": [
    "#train_dataset = load_and_cache_examples(tokenizer, labels, pad_token_label_id, mode=\"train\")\n",
    "with torch.cuda.device(n_gpu):\n",
    "    global_step, tr_loss = train(train_dataset, model, tokenizer, labels, pad_token_label_id)\n",
    "    print(\" global_step = %s, average loss = %s\", global_step, tr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_bert.BertTokenizer at 0x7f30ae2615f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints = [\"test_BERT_eval_during_train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = {}\n",
    "# eval_dataset = load_and_cache_examples(args, tokenizer, labels, pad_token_label_id, mode=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_sampler = SequentialSampler(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = pd.read_csv(\"../test_m_short.txt\", sep='\\t', encoding=\"latin1\").fillna(method=\"ffill\")\n",
    "\n",
    "getter = SentenceGetter(testdata)\n",
    "\n",
    "len(getter.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_test = [[s[0] for s in sent] for sent in getter.sentences]\n",
    "labels_test = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "\n",
    "num_labels = len(labels_test)\n",
    "\n",
    "examples_test = [InputExample(guid, words, labels) for guid, (words, labels) in enumerate(zip(sentences_test, labels_test))]\n",
    "\n",
    "len(examples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Example ***\n",
      "guid: %s 11\n",
      "tokens: %s [CLS] < abstract > we introduce a new method for efficiently sim ##ulating liquid with extreme amounts of spatial adapt ##ivity . [SEP]\n",
      "input_ids: %s 101 1026 10061 1028 2057 8970 1037 2047 4118 2005 18228 21934 10924 6381 2007 6034 8310 1997 13589 15581 7730 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "input_mask: %s 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "segment_ids: %s 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "label_ids: %s -100 0 0 0 0 0 0 0 0 0 0 0 -100 0 0 0 0 0 0 0 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "36\n",
      "tensor([[-100,    0,    0,  ..., -100,    0, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0, -100,  ..., -100, -100, -100],\n",
      "        ...,\n",
      "        [-100,    1,    2,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100],\n",
      "        [-100,    0,    0,  ..., -100, -100, -100]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(1):\n",
    "    device = \"cuda\"\n",
    "    possible_labels = [\"O\", \"B-claim\", \"I-claim\"]\n",
    "    features_test = convert_examples_to_features(examples_test, possible_labels, 50, tokenizer,\n",
    "                                                    cls_token_at_end=False,\n",
    "                                                    # xlnet has a cls token at the end\n",
    "                                                    cls_token=tokenizer.cls_token,\n",
    "                                                    cls_token_segment_id=0,\n",
    "                                                    sep_token=tokenizer.sep_token,\n",
    "                                                    sep_token_extra=False,\n",
    "                                                    # roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805\n",
    "                                                    pad_on_left=False,\n",
    "                                                    # pad on the left for xlnet\n",
    "                                                    pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "                                                    pad_token_segment_id=0,\n",
    "                                                    pad_token_label_id=pad_token_label_id\n",
    "                                                    )\n",
    "\n",
    "    print(len(features_test))\n",
    "        # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features_test], dtype=torch.long).to(device)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features_test], dtype=torch.long).to(device)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features_test], dtype=torch.long).to(device)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in features_test], dtype=torch.long).to(device)\n",
    "    print(all_label_ids)\n",
    "\n",
    "    test_dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating:  20%|██        | 1/5 [00:00<00:00,  6.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.0312,  0.3613, -0.4594,  ...,  0.4336,  0.4693,  0.0137],\n",
      "         [ 0.0873, -0.0297,  0.3326,  ...,  0.1856, -0.3763,  0.2610],\n",
      "         [ 0.1595, -0.1624,  0.1918,  ...,  0.1285,  0.2487, -0.0732],\n",
      "         ...,\n",
      "         [ 0.1833, -0.0594, -0.0156,  ...,  0.0214, -0.2107, -0.0089],\n",
      "         [ 0.5880, -0.1975,  0.0153,  ..., -0.3094,  0.3273, -0.0809],\n",
      "         [-0.0802,  0.1822, -0.0763,  ..., -0.2808,  0.5590, -0.1955]],\n",
      "\n",
      "        [[ 0.1007,  0.4859, -0.4418,  ...,  0.2053,  0.3504,  0.1614],\n",
      "         [ 0.0248,  0.1275,  0.3337,  ...,  0.1054, -0.2797,  0.3138],\n",
      "         [ 0.2574,  0.0589,  0.0108,  ..., -0.0288, -0.2933,  0.0314],\n",
      "         ...,\n",
      "         [ 0.3397, -0.0125, -0.0254,  ...,  0.0068, -0.0972, -0.2804],\n",
      "         [ 0.6195, -0.3266, -0.0448,  ..., -0.4077, -0.3333,  0.3048],\n",
      "         [-0.0184,  0.5473, -0.3238,  ...,  0.0255, -0.0113, -0.2949]],\n",
      "\n",
      "        [[ 0.1245,  0.0950, -0.3904,  ...,  0.0606, -0.0280,  0.1485],\n",
      "         [-0.0889, -0.0579,  0.1897,  ...,  0.2306,  0.2798,  0.3178],\n",
      "         [ 0.0449,  0.0459, -0.0749,  ...,  0.2743, -0.3912, -0.1843],\n",
      "         ...,\n",
      "         [ 0.2858, -0.0924, -0.0642,  ..., -0.2391,  0.0037,  0.2696],\n",
      "         [ 0.3846,  0.0679, -0.2077,  ..., -0.2381,  0.0393,  0.2930],\n",
      "         [ 0.3459, -0.0596, -0.3362,  ...,  0.0139, -0.0475,  0.1146]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2325,  0.1302, -0.3310,  ...,  0.1070,  0.2249, -0.0732],\n",
      "         [-0.1121,  0.0875,  0.2414,  ..., -0.2870, -0.4588,  0.0272],\n",
      "         [ 0.0367, -0.1318,  0.1715,  ...,  0.0857, -0.5640, -0.2570],\n",
      "         ...,\n",
      "         [ 0.2404,  0.0238, -0.0570,  ..., -0.2409, -0.1094, -0.0566],\n",
      "         [ 0.1231, -0.0272, -0.0019,  ..., -0.2817, -0.1218, -0.2209],\n",
      "         [ 0.0758, -0.1462,  0.1327,  ...,  0.0140, -0.1090, -0.0030]],\n",
      "\n",
      "        [[-0.0267, -0.0194, -0.0400,  ..., -0.2791,  0.6547,  0.1365],\n",
      "         [ 0.1738,  0.1462,  0.2873,  ...,  0.3163, -0.4259, -0.1908],\n",
      "         [ 0.2301,  0.1306, -0.2541,  ..., -0.4682, -0.2871, -0.2601],\n",
      "         ...,\n",
      "         [ 0.1778, -0.0907,  0.1374,  ..., -0.1120, -0.1140,  0.1733],\n",
      "         [ 0.2327, -0.1321,  0.1240,  ..., -0.1511, -0.0583,  0.0849],\n",
      "         [ 0.1558,  0.0380, -0.0112,  ...,  0.0175, -0.0692,  0.1287]],\n",
      "\n",
      "        [[ 0.4300, -0.1182, -0.1594,  ..., -0.2664,  0.1564, -0.1731],\n",
      "         [ 0.5914, -0.2463,  0.0551,  ..., -0.1567,  0.1904,  0.0040],\n",
      "         [ 0.2571,  0.8706, -0.6548,  ..., -0.2931, -0.0487, -0.3254],\n",
      "         ...,\n",
      "         [ 0.4552,  0.0427,  0.1639,  ..., -0.3896,  0.2110,  0.2654],\n",
      "         [ 0.5108,  0.0526,  0.1338,  ..., -0.3363,  0.2135,  0.2792],\n",
      "         [ 0.4466,  0.0373,  0.2027,  ..., -0.4604,  0.1625,  0.3421]]],\n",
      "       device='cuda:1'),)\n",
      "PREDS\n",
      "[[11584 15440 14335  8079  6498 11823 12058 16574  6543  4370  2119  2403\n",
      "   1474  4752 11802 16574  6543  8645  7277  6498  4172 11802  7277  6543\n",
      "   1241  6498  9205  1093  1474  7942 14061 16574  6543  4370  1357  4818\n",
      "  11823  2416 16574  6543  1532 13733 14083 16574 16574  6543 13206 16541\n",
      "  14335 15859]\n",
      " [11584 12587  5057  1873  6498  7721  1663 15440 14061 16574  4806  4780\n",
      "    913  3952 10296 16574 11935  4780 12358 10757 14061 14061  6543  7314\n",
      "   9267   733  6251 16160  7721  5691  7721 13694 13397 11185  2416 16574\n",
      "   6543  7314  9387  7351  4172 14061 16574 14999  4780 10991  6498 10991\n",
      "  14335 15859]\n",
      " [12596 15829 16247    11   808 12245  7543   314  1474  5069  2506   325\n",
      "   6596 13598  9293 13598 12427  6498  6802  4504 13598  4504 10991  3686\n",
      "  13598  7448  1233  6498 13598  4504  2226   808  3880  4504 12856 12856\n",
      "  13222 12190 10991  4504  7277  4504 10991  4160  6498  9095  6802 13966\n",
      "  13966 13966]\n",
      " [11584  2592  1337  6498 12157 15257 11260  9013  9013  2927  2927  2927\n",
      "  11260  2592 11260 11260  2927  1337  2927  1709  2927 11260  2927  2927\n",
      "   2927  1709  2927 11260  2592  1337  4160  1709  1709  2927  2927  2927\n",
      "   2927  2927  2927  2927  2927 11260 11260  2592  1337  1709  1709  2927\n",
      "  11260  2927]\n",
      " [11584  9805 15859   733 15290 12495  5125 11592  7891 13048   733  5831\n",
      "  13827 13048  7891  8865 15800  7772 15896  3509  4706  7772  4806  2302\n",
      "  15991  4371 12368 12368 12368 14009  3771  9849 12076  7277 12076 15152\n",
      "  11592  8454  3624  1201 15086  7295 12167  3087  1314  4160 12000  2416\n",
      "   1314 11998]\n",
      " [11584 15363 13280 12495 10740  4729 11086  2989 13574  1171 11558 12540\n",
      "  12011  2836 15363  7351   967  5686  2286  4144  4144  4144 11647   732\n",
      "    732 14091  4144  9254  8341  7942  4932  5395  5164 11086  9254 12428\n",
      "  11086  3256  2294 11086 15234 15234  4932  8341  5517   732  5164   732\n",
      "  11321  5395]\n",
      " [ 5431 11168 13048   267 13048 12587 13827  8768  4504 11472  9024 13827\n",
      "   5143 13827  9315 11991  6132 13048   160 13827  4247  7334  4247 15257\n",
      "  15257  4734  5849  5849  5284  3235  1337 10218  4734  5459 11472  5459\n",
      "  11472 11472   325 14904  1993 10425  1993  4949  2305 10218 10218  4247\n",
      "  11472 11472]\n",
      " [12911 10218  1211  1211 10218  1211  1211 10218 10218 13058 10218  1211\n",
      "   1211 10218 10218 10218 10218 13058  1211 13058  1211  1211 10218 10218\n",
      "  10218 10218  1211 13058 10218 10218 10218 10218  1211 13058 10218 10218\n",
      "  10218 10218 10218 13058 10218 10218 10218 10218 10218 13058 10218 13058\n",
      "  10218 10218]]\n",
      "VERDADERAS\n",
      "tensor([[-100,    0,    0,    0,    0, -100,    0, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100,    0, -100,    0, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,    0,\n",
      "         -100,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "            0, -100],\n",
      "        [-100,    0,    0,    0, -100,    0,    0, -100,    0, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100,    0, -100,    0, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100],\n",
      "        [-100,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100],\n",
      "        [-100,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100],\n",
      "        [-100,    0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100],\n",
      "        [-100,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100,\n",
      "            0, -100,    0,    0, -100,    0, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100],\n",
      "        [-100,    0, -100, -100,    0, -100,    0,    0,    0, -100, -100,    0,\n",
      "            0,    0,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100],\n",
      "        [-100,    0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100]], device='cuda:1')\n",
      "(tensor([[[-0.1825,  0.2113, -0.0487,  ...,  0.1883,  0.5912, -0.2727],\n",
      "         [ 0.2486, -0.1158, -0.0136,  ..., -0.0631, -0.0131, -0.3587],\n",
      "         [ 0.6157, -0.0020, -0.0303,  ..., -0.0563, -0.6269, -0.0905],\n",
      "         ...,\n",
      "         [-0.1677,  0.1751,  0.0068,  ..., -0.0138,  0.1797, -0.2373],\n",
      "         [-0.2409,  0.3618,  0.1404,  ..., -0.0943, -0.2746, -0.2903],\n",
      "         [ 0.1604,  0.1126,  0.2321,  ...,  0.1509, -0.4877, -0.1331]],\n",
      "\n",
      "        [[-0.1483,  0.2108, -0.4305,  ..., -0.0103,  0.6614, -0.0490],\n",
      "         [-0.2891,  0.2635,  0.5219,  ..., -0.2081, -0.3270, -0.2203],\n",
      "         [-0.0603, -0.0647,  0.5738,  ...,  0.0936, -0.5136, -0.4001],\n",
      "         ...,\n",
      "         [ 0.4118,  0.0265, -0.1252,  ..., -0.1826,  0.1365, -0.1280],\n",
      "         [ 0.3650, -0.0076,  0.1148,  ..., -0.2196, -0.0349,  0.0154],\n",
      "         [ 0.3308, -0.0682, -0.2120,  ..., -0.0237, -0.2054, -0.0524]],\n",
      "\n",
      "        [[ 0.0717,  0.5437,  0.0777,  ..., -0.0160,  0.4452, -0.0046],\n",
      "         [ 0.0621,  0.9883, -0.7130,  ..., -0.9627, -0.0316,  0.1139],\n",
      "         [ 0.1244, -0.0772,  0.1780,  ..., -0.0509, -0.2203, -0.1039],\n",
      "         ...,\n",
      "         [ 0.2020,  0.6019, -0.6942,  ...,  0.2523, -0.2500,  0.0652],\n",
      "         [ 0.1880,  0.4577, -0.2580,  ..., -0.0264, -0.0640, -0.1520],\n",
      "         [-0.0075,  0.4509,  0.1851,  ..., -0.4930, -0.1062, -0.0888]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1929,  0.2224, -0.2601,  ..., -0.1933,  0.1224, -0.1550],\n",
      "         [ 0.6729, -0.2022,  0.0707,  ...,  0.2294, -0.2052, -0.1514],\n",
      "         [ 0.1307,  0.3240,  0.0803,  ...,  0.2646, -0.5194, -0.1765],\n",
      "         ...,\n",
      "         [-0.0412, -0.0061,  0.0553,  ..., -0.1256, -0.1379,  0.1964],\n",
      "         [ 0.6207, -0.0940,  0.0390,  ..., -0.1493, -0.0875,  0.0013],\n",
      "         [ 0.5000,  0.7625,  0.3377,  ..., -0.1672,  0.0911, -0.5082]],\n",
      "\n",
      "        [[-0.1913,  0.2284, -0.3844,  ...,  0.0606,  0.6132,  0.1794],\n",
      "         [-0.1070, -0.0347, -0.1923,  ..., -0.0805,  0.2200,  0.3476],\n",
      "         [ 0.5478,  0.0806,  0.1826,  ...,  0.1103, -0.3286, -0.0170],\n",
      "         ...,\n",
      "         [ 0.3643,  1.0596, -0.2056,  ..., -0.3627, -0.5067, -0.6967],\n",
      "         [ 0.3316, -0.2226,  0.1734,  ..., -0.0763, -0.0453, -0.0553],\n",
      "         [ 0.3754,  0.2414, -0.2375,  ..., -0.5081, -0.3772,  0.1222]],\n",
      "\n",
      "        [[-0.0153,  0.1177,  0.0253,  ..., -0.2443,  0.1048, -0.2491],\n",
      "         [ 0.1188, -0.1125,  0.0506,  ...,  0.2191, -0.4093, -0.0759],\n",
      "         [ 0.3006,  0.7572, -0.2736,  ..., -0.1812, -0.1399, -0.7465],\n",
      "         ...,\n",
      "         [ 0.0858, -0.0570, -0.1605,  ..., -0.0194,  0.2136,  0.1284],\n",
      "         [-0.0679,  0.0821, -0.1102,  ..., -0.0749, -0.1386,  0.1315],\n",
      "         [-0.2042, -0.0028,  0.0457,  ..., -0.1177,  0.6681,  0.0780]]],\n",
      "       device='cuda:1'),)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-e3d0a3c29c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mout_label_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_label_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         logits = logits.detach().cpu().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "eval_loss = 0.0\n",
    "nb_eval_steps = 0\n",
    "preds = None\n",
    "out_label_ids = None\n",
    "model.eval()\n",
    "device = \"cuda\"\n",
    "with torch.cuda.device(1):\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            b_input_ids, b_input_mask, b_token_type_ids, b_labels = batch\n",
    "#             inputs = {\"input_ids\": batch[0],\n",
    "#                       \"attention_mask\": batch[1],\n",
    "#                       \"token_type_ids\": batch[2],\n",
    "#                       # XLM and RoBERTa don\"t use segment_ids\n",
    "#                       \"labels\": batch[3]}\n",
    "            loss = model(b_input_ids, attention_mask=b_input_mask, token_type_ids=b_token_type_ids, labels=b_labels)\n",
    "            logits = model(b_input_ids, attention_mask=b_input_mask, token_type_ids=b_token_type_ids)\n",
    "            print(logits)\n",
    "#         tmp_eval_loss, logits = outputs[:2]\n",
    "            \n",
    "            \n",
    "            eval_loss += tmp_eval_loss.item()\n",
    "        nb_eval_steps += 1\n",
    "        if preds is None:\n",
    "            preds = logits[0].detach().cpu().numpy()\n",
    "            out_label_ids = b_labels.detach().cpu().numpy()\n",
    "            print(\"PREDS\")\n",
    "            print(np.argmax(preds, axis=2))\n",
    "            print(\"VERDADERAS\")\n",
    "            print(inputs['labels'])\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "#         logits = logits.detach().cpu().numpy()\n",
    "#         #Capaz esto es voraz\n",
    "#         preds.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "#         out_label_ids.append(inputs[\"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_label_ids.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "15440",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c72315a558ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout_label_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpad_token_label_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mout_label_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_label_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mpreds_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     results = {\n",
      "\u001b[0;31mKeyError\u001b[0m: 15440"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(1):\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "\n",
    "    label_map = {i: label for i, label in enumerate(labels_test)}\n",
    "\n",
    "    out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "    preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "\n",
    "    for i in range(out_label_ids.shape[0]):\n",
    "        for j in range(out_label_ids.shape[1]):\n",
    "            if out_label_ids[i, j] != pad_token_label_id:\n",
    "                out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
    "                preds_list[i].append(label_map[preds[i][j]])\n",
    "\n",
    "    results = {\n",
    "        \"loss\": eval_loss,\n",
    "        \"precision\": precision_score(out_label_list, preds_list),\n",
    "        \"recall\": recall_score(out_label_list, preds_list),\n",
    "        \"f1\": f1_score(out_label_list, preds_list)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "tensor(-100, device='cuda:1')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f1697f833e91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_tags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: tensor(-100, device='cuda:1')"
     ]
    }
   ],
   "source": [
    "label_map[valid_tags[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
